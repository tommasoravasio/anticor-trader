{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "704d7e34",
   "metadata": {},
   "source": [
    "# 00 ‚Äî CRSP Data Download (S&P 500 Top 25)\n",
    "\n",
    "This notebook connects to WRDS, selects the top 25 S&P 500 stocks by market capitalization at a target date, and downloads daily returns over a window covering the last 1,276 trading days. Data and metadata are saved to `data/` for reuse in other notebooks without re-querying WRDS.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "You need a `.env` file in the project root with your WRDS credentials:\n",
    "```\n",
    "WRDS_USERNAME=your_wrds_username\n",
    "WRDS_PASSWORD=your_wrds_password\n",
    "```\n",
    "\n",
    "Copy `.env.example` to `.env` and fill in your credentials. The `.env` file is gitignored for security.\n",
    "\n",
    "## Saved outputs\n",
    "\n",
    "- `data/daily_data_top25.csv` ‚Äî Daily data (permno, date, ret, dlret, comnam, ticker)\n",
    "- `data/permno_to_name.json` ‚Äî Mapping PERMNO ‚Üí Company name\n",
    "- `data/permno_to_ticker.json` ‚Äî Mapping PERMNO ‚Üí Ticker\n",
    "- `data/final_dates.json` ‚Äî List of dates (ISO) in the final window\n",
    "- `data/download_metadata.json` ‚Äî Parameters used and result summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71299d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Connecting to WRDS and setting parameters‚Ä¶\n",
      "Loading library list...\n",
      "Loading library list...\n",
      "Done\n",
      "‚úÖ Connected to WRDS.\n",
      "üìÖ Last trading day selected: 2024-12-31\n",
      "\n",
      "üöÄ Selecting universe (Top 25 S&P 500)‚Ä¶\n",
      "Done\n",
      "‚úÖ Connected to WRDS.\n",
      "üìÖ Last trading day selected: 2024-12-31\n",
      "\n",
      "üöÄ Selecting universe (Top 25 S&P 500)‚Ä¶\n",
      "‚úÖ Universe identified: 25 stocks.\n",
      "\n",
      "üöÄ Downloading daily data (RET, DLRET, COMNAM, TICKER)‚Ä¶\n",
      "‚úÖ Universe identified: 25 stocks.\n",
      "\n",
      "üöÄ Downloading daily data (RET, DLRET, COMNAM, TICKER)‚Ä¶\n",
      "‚úÖ Download completed.\n",
      "\n",
      "üíæ Saving outputs to ../data/ ‚Ä¶\n",
      "‚úÖ Download completed.\n",
      "\n",
      "üíæ Saving outputs to ../data/ ‚Ä¶\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "keys must be str, int, float, bool or None, not int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 115\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Save files\u001b[39;00m\n\u001b[1;32m    114\u001b[0m daily_data\u001b[38;5;241m.\u001b[39mto_csv(daily_csv_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(permno_to_name_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: json\u001b[38;5;241m.\u001b[39mdump(permno_to_name, f, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(permno_to_ticker_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: json\u001b[38;5;241m.\u001b[39mdump(permno_to_ticker, f, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(final_dates_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: json\u001b[38;5;241m.\u001b[39mdump(final_dates_iso, f, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/json/encoder.py:432\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/json/encoder.py:377\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeys must be str, int, float, bool or None, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    378\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first:\n\u001b[1;32m    380\u001b[0m     first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: keys must be str, int, float, bool or None, not int64"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wrds\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file (look in parent directory)\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "# =============================================================================\n",
    "# PARAMETERS\n",
    "# =============================================================================\n",
    "end_date = '2025-01-30'              # Desired calendar date (will be adjusted to last trading day)\n",
    "trading_days = 1276                  # ~ 5 years of trading days\n",
    "num_stocks = 25                      # Universe size\n",
    "start_date_approx = (pd.to_datetime(end_date) - pd.to_timedelta(trading_days * 1.8, unit='d')).strftime('%Y-%m-%d')\n",
    "\n",
    "print('üöÄ Connecting to WRDS and setting parameters‚Ä¶')\n",
    "\n",
    "# Get WRDS credentials from environment variables\n",
    "wrds_username = os.getenv('WRDS_USERNAME')\n",
    "wrds_password = os.getenv('WRDS_PASSWORD')\n",
    "\n",
    "if not wrds_username:\n",
    "    raise ValueError(\"WRDS_USERNAME not found in .env file. Please add it.\")\n",
    "\n",
    "# Connect to WRDS with credentials\n",
    "if wrds_password:\n",
    "    db = wrds.Connection(wrds_username=wrds_username, wrds_password=wrds_password)\n",
    "else:\n",
    "    # If no password is provided, WRDS will prompt or use pgpass\n",
    "    db = wrds.Connection(wrds_username=wrds_username)\n",
    "\n",
    "print('‚úÖ Connected to WRDS.')\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: FIND LAST TRADING DAY <= end_date\n",
    "# =============================================================================\n",
    "query_last_date = f\"SELECT max(date) as last_date FROM crsp.dsf WHERE date <= '{end_date}'\"\n",
    "last_date_df = db.raw_sql(query_last_date, date_cols=['last_date'])\n",
    "last_trading_day_str = last_date_df['last_date'][0].strftime('%Y-%m-%d')\n",
    "end_date = last_trading_day_str\n",
    "print(f'üìÖ Last trading day selected: {end_date}')\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: BUILD UNIVERSE (TOP 25 S&P 500 by market cap)\n",
    "# =============================================================================\n",
    "print('\\nüöÄ Selecting universe (Top 25 S&P 500)‚Ä¶')\n",
    "query_universe = f\"\"\"\n",
    "    WITH sp500_constituents AS (\n",
    "        SELECT permno FROM crsp.msp500list WHERE '{end_date}' BETWEEN start AND ending\n",
    "    ),\n",
    "    market_cap AS (\n",
    "        SELECT a.permno, ABS(a.prc * a.shrout) as mktcap\n",
    "        FROM crsp.dsf AS a\n",
    "        JOIN sp500_constituents AS b ON a.permno = b.permno\n",
    "        WHERE a.date = '{end_date}' AND a.prc IS NOT NULL AND a.shrout IS NOT NULL\n",
    "    )\n",
    "    SELECT permno FROM market_cap ORDER BY mktcap DESC LIMIT {num_stocks}\n",
    "\"\"\"\n",
    "top_25_permno = db.raw_sql(query_universe)['permno'].tolist()\n",
    "permno_tuple = tuple(top_25_permno)\n",
    "print(f'‚úÖ Universe identified: {len(top_25_permno)} stocks.')\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: DOWNLOAD HISTORICAL DATA (RET, DLRET, + LABELS)\n",
    "# =============================================================================\n",
    "print('\\nüöÄ Downloading daily data (RET, DLRET, COMNAM, TICKER)‚Ä¶')\n",
    "query_data = f\"\"\"\n",
    "    SELECT a.permno, a.date, a.ret, b.dlret, c.comnam, c.ticker\n",
    "    FROM crsp.dsf AS a\n",
    "    LEFT JOIN crsp.dsedelist AS b\n",
    "        ON a.permno = b.permno AND a.date = b.dlstdt\n",
    "    LEFT JOIN crsp.msenames AS c\n",
    "        ON a.permno = c.permno AND a.date BETWEEN c.namedt AND c.nameendt\n",
    "    WHERE a.permno IN {permno_tuple} AND a.date BETWEEN '{start_date_approx}' AND '{end_date}'\n",
    "\"\"\"\n",
    "daily_data = db.raw_sql(query_data, date_cols=['date'])\n",
    "\n",
    "# Fill missing comnam/ticker labels by PERMNO (ffill/bfill to cover gaps)\n",
    "daily_data['comnam'] = daily_data.groupby('permno')['comnam'].transform(lambda x: x.ffill().bfill())\n",
    "daily_data['ticker'] = daily_data.groupby('permno')['ticker'].transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "# Create useful mappings (convert numpy int64 keys to regular Python int for JSON compatibility)\n",
    "permno_to_name = {int(k): v for k, v in daily_data.drop_duplicates('permno').set_index('permno')['comnam'].to_dict().items()}\n",
    "permno_to_ticker = {int(k): v for k, v in daily_data.drop_duplicates('permno').set_index('permno')['ticker'].to_dict().items()}\n",
    "\n",
    "# Limit to the last 1,276 trading days actually present\n",
    "all_dates = sorted(daily_data['date'].unique())\n",
    "final_dates = all_dates[-trading_days:] if len(all_dates) >= trading_days else all_dates\n",
    "daily_data = daily_data[daily_data['date'].isin(final_dates)]\n",
    "\n",
    "print('‚úÖ Download completed.')\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE RESULTS TO ../data/ (parent directory)\n",
    "# =============================================================================\n",
    "print('\\nüíæ Saving outputs to ../data/ ‚Ä¶')\n",
    "data_dir = os.path.join('..', 'data')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "daily_csv_path = os.path.join(data_dir, 'daily_data_top25.csv')\n",
    "permno_to_name_path = os.path.join(data_dir, 'permno_to_name.json')\n",
    "permno_to_ticker_path = os.path.join(data_dir, 'permno_to_ticker.json')\n",
    "final_dates_path = os.path.join(data_dir, 'final_dates.json')\n",
    "meta_path = os.path.join(data_dir, 'download_metadata.json')\n",
    "\n",
    "# Convert dates to ISO for JSON\n",
    "final_dates_iso = [pd.to_datetime(d).strftime('%Y-%m-%d') for d in final_dates]\n",
    "\n",
    "# Save files\n",
    "daily_data.to_csv(daily_csv_path, index=False)\n",
    "with open(permno_to_name_path, 'w', encoding='utf-8') as f: \n",
    "    json.dump(permno_to_name, f, ensure_ascii=False, indent=2)\n",
    "with open(permno_to_ticker_path, 'w', encoding='utf-8') as f: \n",
    "    json.dump(permno_to_ticker, f, ensure_ascii=False, indent=2)\n",
    "with open(final_dates_path, 'w', encoding='utf-8') as f: \n",
    "    json.dump(final_dates_iso, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "metadata = {\n",
    "    'generated_at': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "    'parameters': {\n",
    "        'requested_end_date': end_date,\n",
    "        'trading_days_target': trading_days,\n",
    "        'num_stocks': num_stocks,\n",
    "        'start_date_approx': start_date_approx\n",
    "    },\n",
    "    'universe': {\n",
    "        'count': len(top_25_permno),\n",
    "        'permnos': top_25_permno\n",
    "    },\n",
    "    'date_window': {\n",
    "        'start': final_dates_iso[0] if final_dates_iso else None,\n",
    "        'end': final_dates_iso[-1] if final_dates_iso else None,\n",
    "        'n_trading_days': len(final_dates_iso)\n",
    "    },\n",
    "    'files': {\n",
    "        'daily_csv': daily_csv_path,\n",
    "        'permno_to_name': permno_to_name_path,\n",
    "        'permno_to_ticker': permno_to_ticker_path,\n",
    "        'final_dates': final_dates_path\n",
    "    }\n",
    "}\n",
    "with open(meta_path, 'w', encoding='utf-8') as f: \n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print('üìÅ Files written:')\n",
    "print(' -', daily_csv_path)\n",
    "print(' -', permno_to_name_path)\n",
    "print(' -', permno_to_ticker_path)\n",
    "print(' -', final_dates_path)\n",
    "print(' -', meta_path)\n",
    "\n",
    "# =============================================================================\n",
    "# CLOSE WRDS CONNECTION\n",
    "# =============================================================================\n",
    "db.close()\n",
    "print('üîí WRDS connection closed.')\n",
    "\n",
    "print('\\nüéâ Done. You can now load these files from ../data/ in your other notebooks.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
